{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Representation of Text Data\n",
    "### Author: Ariel Cintron, Ph.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has the following objectives:\n",
    "1. Read the text data.\n",
    "2. Convert text into smaller units called tokens.\n",
    "3. Evaluate basic functions for text processing involving stop word and punctuation removal.\n",
    "4. Transform text data into a numerical matrix of token counts while using Python tools.\n",
    "5. Visualize text data with heatmap plots of matrix representations for text data.\n",
    "6. Explore rank and singular values for document-term matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Python Modules\n",
    "If needed, use `pip install` and then re-start the Kernell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset stored in the file `SMSSpamCollection.tsv` is available in the UCI Machine Learning Repository:\n",
    "https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"data/SMSSpamCollection.tsv\", sep='\\t')\n",
    "data1.columns = ['label', 'body_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info() # summary of tabular data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape # number of rows and columns in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head() # inspecting the top rows in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['label'].unique() # distinct classes in categorical feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Processing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [ps.stem(word) for word in tokenized_list if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['body_text_nopunct'] = data1['body_text'].apply(lambda x: remove_punct(x))\n",
    "data1['body_text_tokenized'] = data1['body_text_nopunct'].apply(lambda x: tokenize(x))\n",
    "data1['body_nostopw'] = data1['body_text_tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Term Matrix\n",
    "\n",
    "https://en.wikipedia.org/wiki/Document-term_matrix\n",
    "\n",
    "A document-term matrix is a mathematical matrix that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms. \n",
    "\n",
    "Document-term matrices may be calcualted by deploying `CountVectorizer()` from the Scikit-Learn module:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=clean_text) #Instatiating CountVectorizer()\n",
    "\n",
    "X1_counts = count_vect.fit_transform(data1['body_text'])\n",
    "\n",
    "### Sample or subset of original matrix\n",
    "scalar_multiple = 7 # fill in with a positive integer less than 7 to set sample size as a multiple of 10\n",
    "rows_in_sample = (scalar_multiple)*10 \n",
    "data1_sample = data1[0:rows_in_sample]\n",
    "count_vect_sample1 = CountVectorizer(analyzer=clean_text)\n",
    "X1_counts_sample = count_vect.fit_transform(data1_sample['body_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the number of rows and columns for the original document-term matrix versus a sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensions of original document-term matrix = {}'.format(X1_counts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensions of sample document-term matrix = {}'.format(X1_counts_sample.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color-Coded Representation of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heat map is a color-coded representation of the entries of a matrix, where\n",
    "zero is coded with the color white and larger positive integer values\n",
    "are coded in the darker-color spectrum.\n",
    "\n",
    "The original 5567-by-8104 document-term matrix is very sparse (that is, it has\n",
    "multiple entries equal to zero). Thus, its heat map\n",
    "representation displays most regions with tones ranging form light-blue to white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=1, nrows=2, figsize=(15,12),layout=\"constrained\")\n",
    "sns.heatmap(X1_counts.todense(),cmap='Blues',ax=axs[0])\n",
    "axs[0].set_title('Document-Term Matrix Dimensions = {}'.format(X1_counts.shape))\n",
    "sns.heatmap(X1_counts_sample.todense(),cmap='Blues',ax=axs[1])\n",
    "axs[1].set_title('Document-Term Matrix Dimensions = {}'.format(X1_counts_sample.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,V = np.linalg.svd(X1_counts.todense())\n",
    "U1,S1,V1 = np.linalg.svd(X1_counts_sample.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the rank of the original matrix versus sample matrix?\n",
    "Hint: The attribute `.shape` gives pertinent information about the number of singular values which is then employed to establish the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The rank of the original document-term matrix is {}'.format(S.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The rank of the sample document-term matrix is {}'.format(S1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the smallest and largest singular values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The smallest singular value in the original document-term matrix is {}'.format(S.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The smallest singular value in the sample matrix is {}'.format(S1.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The largest singular value in the original document-term matrix equals {}'.format(S.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The largest singular value in the sample matrix is {}'.format(S1.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we display the singular values in semi-logarithmic scale for both the original document-term matrix and the sample matrix. The singular values are plotted in the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsvd, axssvd = plt.subplots(ncols=2, nrows=1, figsize=(15,10),layout=\"constrained\")\n",
    "axssvd[0].semilogy(S)\n",
    "axssvd[0].set_title('Document-Term Matrix Dimensions = {}'.format(X1_counts.shape))\n",
    "axssvd[0].set_ylabel('Log(Singular Values)')\n",
    "axssvd[1].semilogy(S1) \n",
    "axssvd[1].set_title('Document-Term Matrix Dimensions = {}'.format(X1_counts_sample.shape))\n",
    "axssvd[1].set_ylabel('Log(Singular Values)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
